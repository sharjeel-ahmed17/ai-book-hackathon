"use strict";(self.webpackChunkai_book_hackathon=self.webpackChunkai_book_hackathon||[]).push([[129],{8453:(e,n,o)=>{o.d(n,{R:()=>r,x:()=>a});var i=o(6540);const t={},s=i.createContext(t);function r(e){const n=i.useContext(s);return i.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function a(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(t):e.components||t:r(e.components),i.createElement(s.Provider,{value:n},e.children)}},9644:(e,n,o)=>{o.r(n),o.d(n,{assets:()=>l,contentTitle:()=>a,default:()=>h,frontMatter:()=>r,metadata:()=>i,toc:()=>d});const i=JSON.parse('{"id":"textbook/vla-humanoid/intro","title":"Weeks 11-13: VLA Models and Humanoid Robotics","description":"This section explores Vision-Language-Action (VLA) models and their applications in humanoid robotics. You\'ll learn how to implement and use VLA models for complex robotic tasks and human-robot interaction.","source":"@site/docs/textbook/vla-humanoid/intro.md","sourceDirName":"textbook/vla-humanoid","slug":"/textbook/vla-humanoid/intro","permalink":"/docs/textbook/vla-humanoid/intro","draft":false,"unlisted":false,"editUrl":"https://github.com/sharjeel-ahmed17/ai-book-hackathon/edit/main/docs/textbook/vla-humanoid/intro.md","tags":[],"version":"current","sidebarPosition":1,"frontMatter":{"sidebar_position":1},"sidebar":"textbookSidebar","previous":{"title":"Weeks 8-10: NVIDIA Isaac","permalink":"/docs/textbook/nvidia-isaac/intro"},"next":{"title":"Capstone: Autonomous Humanoid Pipeline","permalink":"/docs/textbook/capstone/intro"}}');var t=o(4848),s=o(8453);const r={sidebar_position:1},a="Weeks 11-13: VLA Models and Humanoid Robotics",l={},d=[{value:"Learning Objectives",id:"learning-objectives",level:2},{value:"Topics Covered",id:"topics-covered",level:2},{value:"Prerequisites",id:"prerequisites",level:2}];function c(e){const n={h1:"h1",h2:"h2",header:"header",li:"li",p:"p",ul:"ul",...(0,s.R)(),...e.components};return(0,t.jsxs)(t.Fragment,{children:[(0,t.jsx)(n.header,{children:(0,t.jsx)(n.h1,{id:"weeks-11-13-vla-models-and-humanoid-robotics",children:"Weeks 11-13: VLA Models and Humanoid Robotics"})}),"\n",(0,t.jsx)(n.p,{children:"This section explores Vision-Language-Action (VLA) models and their applications in humanoid robotics. You'll learn how to implement and use VLA models for complex robotic tasks and human-robot interaction."}),"\n",(0,t.jsx)(n.h2,{id:"learning-objectives",children:"Learning Objectives"}),"\n",(0,t.jsx)(n.p,{children:"By the end of this section, you will:"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:"Understand Vision-Language-Action (VLA) models"}),"\n",(0,t.jsx)(n.li,{children:"Implement VLA models for robotics applications"}),"\n",(0,t.jsx)(n.li,{children:"Apply VLA models to humanoid robotics tasks"}),"\n",(0,t.jsx)(n.li,{children:"Understand the challenges and opportunities in humanoid robotics"}),"\n",(0,t.jsx)(n.li,{children:"Integrate perception, planning, and control for humanoid systems"}),"\n"]}),"\n",(0,t.jsx)(n.h2,{id:"topics-covered",children:"Topics Covered"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:"Vision-Language-Action models overview"}),"\n",(0,t.jsx)(n.li,{children:"VLA for robotics applications"}),"\n",(0,t.jsx)(n.li,{children:"Humanoid robotics challenges"}),"\n",(0,t.jsx)(n.li,{children:"Manipulation and locomotion"}),"\n",(0,t.jsx)(n.li,{children:"Human-robot interaction"}),"\n",(0,t.jsx)(n.li,{children:"Advanced humanoid control systems"}),"\n"]}),"\n",(0,t.jsx)(n.h2,{id:"prerequisites",children:"Prerequisites"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:"Deep learning knowledge"}),"\n",(0,t.jsx)(n.li,{children:"Understanding of robotics control"}),"\n",(0,t.jsx)(n.li,{children:"Familiarity with perception systems"}),"\n"]})]})}function h(e={}){const{wrapper:n}={...(0,s.R)(),...e.components};return n?(0,t.jsx)(n,{...e,children:(0,t.jsx)(c,{...e})}):c(e)}}}]);